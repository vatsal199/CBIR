{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RE1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X85CeRztsAD3",
        "outputId": "97e34384-407a-4df4-f911-84338cf2f340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive')'''"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU7MjdnluWlf"
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV7TJnZMubk0"
      },
      "source": [
        "basePath = '/content/'\n",
        "#data_dir = basePath+'Sample'\n",
        "data_dir = basePath+'val2017'\n",
        "drive_dir = '/content/drive/My Drive/RE/'\n",
        "\n",
        "input_size = 224\n",
        "batch_size = 2\n",
        "\n",
        "topk = 44\n",
        "filename = 'data.json'"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdvIiBUPudK5"
      },
      "source": [
        "#image_types = [\"Covid-19\",\"No_findings\",\"Pneumonia\"]\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCHFbkoy4uHE",
        "outputId": "e1fbd778-0434-4d91-b4da-99eded6d08bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "'''import zipfile\n",
        "import os\n",
        "for file_name in os.listdir(drive_dir):\n",
        "  if file_name.endswith('.zip'):\n",
        "    with zipfile.ZipFile(drive_dir+file_name,'r') as zip_dir:\n",
        "      zip_dir.extractall(path='/content/')'''"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"import zipfile\\nimport os\\nfor file_name in os.listdir(drive_dir):\\n  if file_name.endswith('.zip'):\\n    with zipfile.ZipFile(drive_dir+file_name,'r') as zip_dir:\\n      zip_dir.extractall(path='/content/')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6jBAzHeufCJ"
      },
      "source": [
        "def resize_and_rename(image_dir):\n",
        "    i = 1\n",
        "    files = glob.glob(os.path.join(image_dir, \"*\"))\n",
        "    for file in files:\n",
        "        im = Image.open(file)\n",
        "        f, e = os.path.splitext(file)\n",
        "        imResize = im.resize((input_size,input_size), Image.ANTIALIAS)\n",
        "        os.remove(file)\n",
        "\n",
        "        path = '/'+os.path.join(*f.split('/')[:-1])+'/'+str(i)\n",
        "        if not os.path.exists(path):\n",
        "          os.mkdir(path) \n",
        "        fullPath = os.path.join(path,str(i))\n",
        "        i+=1\n",
        "        imResize.save(fullPath + '.png', 'PNG', quality=90)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upOikv7VuhBJ",
        "outputId": "e94d5fac-8f7c-4ad3-e2c1-3eccf4f3cf85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "'''!cp -R '/content/drive/My Drive/Sample' '/content/'\n",
        "#!cp -R '/content/drive/My Drive/COVID-19/Dataset_2' '/content/'\n",
        "resize_and_rename(data_dir)'''"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"!cp -R '/content/drive/My Drive/Sample' '/content/'\\n#!cp -R '/content/drive/My Drive/COVID-19/Dataset_2' '/content/'\\nresize_and_rename(data_dir)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQU4LDoDumxZ"
      },
      "source": [
        "def getTrainDataLoaders():\n",
        "    # Data augmentation and normalization for training\n",
        "    # Just normalization for validation\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    }\n",
        "\n",
        "    print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "    # Create training and validation datasets\n",
        "    image_dataset = datasets.ImageFolder(data_dir+'/', data_transforms['val'])\n",
        "    idx2label_dict = {v: k for k, v in image_dataset.class_to_idx.items()}\n",
        "    # Create training and validation dataloaders\n",
        "    dataloader = torch.utils.data.DataLoader(image_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "    \n",
        "    return idx2label_dict,dataloader"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDiAQ63WurVZ"
      },
      "source": [
        "def getOutput(model):\n",
        "    idx2label_dict,dataloaders = getTrainDataLoaders()\n",
        "    label_lookup = np.vectorize(lambda id: np.int32(idx2label_dict[id]))\n",
        "\n",
        "    features = np.asarray([])\n",
        "    feature_labels = []\n",
        "\n",
        "    model.eval()\n",
        "    print(\"Features generation started...\")\n",
        "\n",
        "    i = 0\n",
        "    for inputs, labels in dataloaders:\n",
        "        inputs = inputs.to(device)\n",
        "        #labels = labels.to(device)\n",
        "        sample_fname, _ = dataloaders.dataset.samples[i]\n",
        "        i += 1\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        tempOut = outputs.cpu().detach().numpy()\n",
        "        tempLabel = labels.cpu().detach().numpy()\n",
        "        if features.shape[0] == 0:\n",
        "            features = tempOut\n",
        "            feature_labels = label_lookup(tempLabel)\n",
        "        else:\n",
        "            features = np.append(features, tempOut, axis=0)\n",
        "            feature_labels = np.append(feature_labels,label_lookup(tempLabel), axis=0)\n",
        "        \n",
        "    return features,feature_labels"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE_P54vkzJAh"
      },
      "source": [
        "def ReLU(X):\n",
        "   return np.maximum(0,X)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78PBCq6rzLXw"
      },
      "source": [
        "def CReLU(f):\n",
        "    f_pos = f\n",
        "    f_neg = -f\n",
        "    final_f = np.concatenate((f_pos, f_neg))\n",
        "    return ReLU(final_f)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ4zFyFjzTFy"
      },
      "source": [
        "def getSurrogateText(F,topK):\n",
        "    surrText = \"\"\n",
        "    count = topK\n",
        "    for ele in F:\n",
        "        instanceText = \"RO\"+str(ele)\n",
        "        instanceText += (\" \"+instanceText)*(count-1)\n",
        "        if len(surrText) == 0:\n",
        "            surrText = instanceText\n",
        "        else:\n",
        "            surrText += (\" \"+instanceText)\n",
        "        count -= 1\n",
        "    return surrText"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_xzqzu4zWFi"
      },
      "source": [
        "def F2Text(f,topK):\n",
        "    rf = CReLU(f)\n",
        "    perVec = np.argsort(rf)[::-1]+1\n",
        "    invPer = np.argsort(perVec)+1\n",
        "    after_topk = invPer[invPer <= topK]\n",
        "    return getSurrogateText(after_topk,topK)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7vaGILzzYJy"
      },
      "source": [
        "def getElasticData(fv,labels,topK):\n",
        "    nText = fv.shape[0]\n",
        "    for i in range(nText):\n",
        "        #random.shuffle(li)\n",
        "        surrText = F2Text(fv[i],topK)\n",
        "        data1 = {\"index\":{\"_id\":i+1}}\n",
        "\n",
        "        data2 = {\n",
        "          \"text\": surrText,\n",
        "          \"image\": '/'+str(labels[i])+'/'+str(labels[i])+'.png'\n",
        "        }\n",
        "\n",
        "        with open(filename,'a') as f: \n",
        "            json.dump(data1, f)\n",
        "            f.write('\\n')\n",
        "            json.dump(data2, f)\n",
        "            f.write('\\n')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9si_CefuI4EZ",
        "outputId": "f58f6cb3-16b8-42a6-be0c-7805245f90b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "'''class VGGFeatures(nn.Module):\n",
        "    def __init__(self,vgg):\n",
        "        super(VGGFeatures, self).__init__()\n",
        "        self.features = nn.Sequential(*list(vgg.children())[:-1])\n",
        "        self.feat_vec = nn.Sequential(*list(vgg.children())[2][:-3])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x= self.feat_vec(x)\n",
        "        return x\n",
        "\n",
        "vgg = models.vgg16(pretrained=True)\n",
        "model = VGGFeatures(vgg)\n",
        "model = model.to(device)'''"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'class VGGFeatures(nn.Module):\\n    def __init__(self,vgg):\\n        super(VGGFeatures, self).__init__()\\n        self.features = nn.Sequential(*list(vgg.children())[:-1])\\n        self.feat_vec = nn.Sequential(*list(vgg.children())[2][:-3])\\n        \\n    def forward(self, x):\\n        x = self.features(x)\\n        x = torch.flatten(x, 1)\\n        x= self.feat_vec(x)\\n        return x\\n\\nvgg = models.vgg16(pretrained=True)\\nmodel = VGGFeatures(vgg)\\nmodel = model.to(device)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQHUNOnAZ6qC"
      },
      "source": [
        "class DenseFeatures(nn.Module):\n",
        "    def __init__(self,dense):\n",
        "        super(DenseFeatures, self).__init__()\n",
        "        self.features = nn.Sequential(*list(dense.children())[:-1])\n",
        "        #self.feat_vec = nn.Sequential(*list(dense.children())[2][:-3])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = F.relu(x, inplace=True)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = torch.flatten(x, 1)\n",
        "        #x = torch.flatten(x, 1)\n",
        "        #x= self.feat_vec(x)\n",
        "        return x\n",
        "\n",
        "dense = models.densenet121(pretrained=True)\n",
        "model = DenseFeatures(dense)\n",
        "model = model.to(device)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dTL2CrRUapi"
      },
      "source": [
        "#print(model)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJEot5Mkyjgt",
        "outputId": "ee20e104-30fd-432f-c62d-70d4ae72514e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "out,labels = getOutput(model)\n",
        "print(out.shape,labels.shape)\n",
        "#print(labels)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing Datasets and Dataloaders...\n",
            "Features generation started...\n",
            "(4998, 1024) (4998,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gyyy14azgMs"
      },
      "source": [
        "getElasticData(out,labels,topk)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_UadJKV6aQ-"
      },
      "source": [
        "#!cp  '/content/data.json' '/content/drive/My Drive/RE/' "
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}